% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rwnnet.R
\name{rwnnet}
\alias{rwnnet}
\title{rwnnet: An R/C++ Implementation of Random Weights Neural Networks.}
\usage{
rwnnet(x, y, size, algorithm, skip = TRUE, flat = TRUE, eta = 1)
}
\arguments{
\item{x}{a data.frame or tibble of numeric inputs.}

\item{y}{a numeric vector (regression), a factor (classification) or a
data.frame (tibble) of numeric outputs (multi-output regression).}

\item{size}{a vector of integers defining the width and depth of network, i.e.
c(32, 32) defines two layers with 32 nodes (neurons) each.}

\item{algorithm}{a character with the type of algorithm used to train the
network. See Details.}

\item{skip}{a logical. If TRUE (default) skip connections are added. See
Details.}

\item{flat}{a logical. If TRUE (default) when possible the structure of the
network is flattened - in a deep or multi-layer network - and trained as a
shallow network by using skip or direct connections from each hidden layer
to the output layer.}

\item{eta}{a numeric value. Controls the gaussian noise regularization.
See Details}
}
\description{
rwnnet implements randomized feed-forward neural network where the hidden
layers are random initialized and fixed during training. The network is
fitted in a single-pass by training a regularized least squares read-out
layer - Tikhonov regularization through an efficient SVD-based algorithm.
As an additional regularization mechanism gaussian noise is added both to
the inputs and output(s) of the network.
The key components are written in C++, using Rcpp, and binded to R for
maximum performance and ease-of-use. Shallow and deep network can be
trained using the Extreme Learning Machine and the Random Vector Functional
Link frameworks.  Supports regression, multi-output regression and
classification. Depending on the algorithm chosen it allows to fit an
implicit ensemble model.
}
\details{
TODO
}
\references{
TODO
}
\author{
David Senhora Navega
}
